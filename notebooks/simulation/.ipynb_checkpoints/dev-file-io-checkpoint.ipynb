{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2c942ae-1ae6-4c7b-b5ec-96018e0624c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "from os.path import expanduser\n",
    "## actions required!!!!!!!!!!!!!!!!!!!! change your folder path \n",
    "path_repo = expanduser(\"~/Documents/G3_2/regime-identification\"); sys.path.append(path_repo)\n",
    "path_file = expanduser(\"~/data/G3_2/regime-identification/simulation\")\n",
    "path = {}\n",
    "for folder in [\"data\", \"estimation\", \"score\", \"figure\", \"latex\"]:\n",
    "    path[folder] = f\"{path_file}/{folder}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39d26cb7-de3f-4fb3-a14f-cbeadeddfb92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from regime.simulation_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b583365-05b6-40cd-a0d2-6d8f7156d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_name(path, folder, key_data, name, key_len=None, key_feat=None, key_model=None, job_id=None, suffix=\"npy\"):\n",
    "    file_name = f\"{path[folder]}/{key_data}/{name}\"\n",
    "    if key_len is None:\n",
    "        return file_name + \".\" + suffix\n",
    "    file_name += f\"_{key_len}\"\n",
    "    if key_feat is None:\n",
    "        return file_name + \".\" + suffix\n",
    "    file_name += f\"_{key_feat}\"\n",
    "    if key_model is None:\n",
    "        return file_name + \".\" + suffix\n",
    "    file_name += f\"_{key_model}\"\n",
    "    if job_id is None:\n",
    "        return file_name + \".\" + suffix\n",
    "    return file_name + f\"_{job_id}\" + \".\" + suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aa03aa-7f6b-48b1-9fcd-41ff442ea4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dir_exist(file_name):\n",
    "    dirname = os.path.dirname(file_name)\n",
    "    if not os.path.exists(dirname): \n",
    "        os.makedirs(dirname)  \n",
    "        print(f\"create folder: {dirname}.\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab097e4c-ef49-4270-bf4b-6a4614302ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22db50b4-606a-410e-99b5-fb5de422bfe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_file(arr, path, folder, key_data, name=None, key_len=None, key_feat=None, key_model=None, job_id=None, suffix=\"npy\"):\n",
    "    \"\"\"\n",
    "    save a file, or a dict of files.\n",
    "    \"\"\"\n",
    "    if isinstance(arr, dict):\n",
    "        for name_, arr_ in arr.items():\n",
    "            save_file(arr_, path, folder, key_data, name_, key_len, key_feat, key_model, job_id, suffix)\n",
    "        return\n",
    "    file_name = generate_file_name(path, folder, key_data, name, key_len, key_feat, key_model, job_id, suffix)\n",
    "    check_dir_exist(file_name)\n",
    "    if suffix == \"npy\":\n",
    "        np.save(file_name, arr)\n",
    "        print(f\"shape of the saved {name}: {arr.shape}.\")\n",
    "    elif suffix == \"h5\":\n",
    "        arr.to_hdf(file_name, name, \"w\")\n",
    "        print(f\"save {name} to hdf: {arr.shape}\")\n",
    "    elif suffix == \"csv\":\n",
    "        arr.to_csv(file_name)\n",
    "        print(f\"save {name} to csv: {arr.shape}\")\n",
    "    else: \n",
    "        raise NotImplementedError()\n",
    "    return \n",
    "\n",
    "def load_file(path, folder, key_data, name, key_len=None, key_feat=None, key_model=None, job_id=None, suffix=\"npy\", **kwargs):\n",
    "    \"\"\"\n",
    "    save an arr\n",
    "    \"\"\"\n",
    "    file_name = generate_file_name(path, folder, key_data, name, key_len, key_feat, key_model, job_id, suffix)\n",
    "    if suffix == \"npy\":\n",
    "        return np.load(file_name)\n",
    "    elif suffix == \"h5\":\n",
    "        return pd.read_hdf(file_name)\n",
    "    elif suffix == \"csv\":\n",
    "        return pd.read_csv(file_name, **kwargs)\n",
    "    else: \n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    \n",
    "def save_file_dict(arr_dict, path, folder, key_data, key_len=None, key_feat=None, key_model=None, job_id=None, suffix=\"npy\"):\n",
    "    \"\"\"\n",
    "    save a dict of arrs.\n",
    "    \"\"\"\n",
    "    for name, arr in arr_dict.items():\n",
    "        save_file(arr, path, folder, key_data, name, key_len, key_feat, key_model, job_id, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00615f2f-1cae-4b38-8b72-d6b2b2249188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098e237b-95c4-4637-ac81-11d422df34f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c052ef-0d89-42c1-8f6b-701d1efd93e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d7c64-8d42-4448-8032-5b1650aa72d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_save_print(file_name, arr, arr_name=\"arr\"):\n",
    "    \"\"\"\n",
    "    save one file and print its shape. If the folder doesn't exist, creat one.\n",
    "    \"\"\"\n",
    "    check_dir_exist(file_name)\n",
    "    np.save(file_name, arr)\n",
    "    print(f\"shape of the saved {arr_name}: {arr.shape}.\")\n",
    "    return\n",
    "\n",
    "\n",
    "def print_seconds(x):\n",
    "    x = math.ceil(x)\n",
    "    return str(timedelta(seconds=x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25da82b-8c41-4fd9-b565-cdb2bda9a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit_many_datas_models(key_data_list, key_feat_list, model_dict, param_grid, path, job_id, batch_size, n_s_list=None):\n",
    "    \"\"\"\n",
    "    train a collection of models, w/ hyperparams to tune, on a batch of data from many datasets.\n",
    "    can specify the seq length to fit, or fit all in the folder.\n",
    "    \"\"\"\n",
    "    def raise_str_to_list(x):\n",
    "        if isinstance(x, str): return [x]\n",
    "        return x\n",
    "    key_data_list, key_feat_list = raise_str_to_list(key_data_list), raise_str_to_list(key_feat_list)\n",
    "    #\n",
    "    start = job_id * batch_size; end = start + batch_size\n",
    "    N_combos = len(key_data_list) * len(key_feat_list) * len(model_dict)\n",
    "    count = 0; time_old = time.time(); total_time=0.\n",
    "    for key_data, key_feat in product(key_data_list, key_feat_list):\n",
    "        folder = f\"{path['data']}/{key_data}\"\n",
    "        if n_s_list is not None:\n",
    "            filenames = [generate_file_name(path, \"data\", key_data, \"Xs\", n_s, key_feat) for n_s in n_s_list]\n",
    "        else:\n",
    "            filenames = filter_filenames_in_folder(folder, key_feat)\n",
    "        for key_model, model in model_dict.items():\n",
    "            count+=1; print(f\"{count}/{N_combos} combo starts.\")\n",
    "            for filename in filenames:\n",
    "                Xs = np.load(f\"{folder}/{filename}\")[start:end]\n",
    "                n_s = int(filename.split('_')[1]); Zs = load_file(path, \"data\", key_data, \"Zs\", n_s)[start:end]\n",
    "                # train the model, on a param grid, on a batch of data\n",
    "                model_params_arr, labels_arr, proba_arr = model_fit_batch_with_params(model, Xs, Zs, param_grid)\n",
    "                # save results\n",
    "                save_file({\"modelParams\": model_params_arr,\n",
    "                          \"labels\": labels_arr,\n",
    "                          \"proba\": proba_arr}, \n",
    "                          path, \"estimation\", key_data, None, n_s, key_feat, key_model, job_id)\n",
    "            time_now = time.time(); time_this_iter = time_now-time_old; total_time += time_this_iter; time_old = time_now\n",
    "            print(f\"{count}/{N_combos} combo done. Time of this combo: {print_seconds(time_this_iter)}s. Total time: {print_seconds(total_time)}s.\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe85e4-6f85-428a-9e8e-ebb75f3ae901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(key_feat, key_data, n_b, path, n_s_list = None):\n",
    "    \"\"\"\n",
    "    key_data can be a list\n",
    "    \"\"\"\n",
    "    if isinstance(key_data, list):\n",
    "        for key_data_ in key_data:\n",
    "            feature_engineer(key_feat, key_data_, n_b, path)\n",
    "        return \n",
    "    if isinstance(key_feat, list):\n",
    "        for key_feat_ in key_feat:\n",
    "            feature_engineer(key_feat_, key_data, n_b, path)\n",
    "        return    \n",
    "\n",
    "    function_dict = {\"zhengB\": lambda x: feature_engineer_zheng_batch(x, True),\n",
    "                    \"zhengF\": lambda x: feature_engineer_zheng_batch(x, False),\n",
    "                    \"ewm\": feature_engineer_ewm_batch}\n",
    "    if key_feat not in function_dict.keys():\n",
    "        raise NotImplementedError(\"feature not supported yet\") \n",
    "    \n",
    "    # key_feat, key_data are single key\n",
    "    folder = f\"{path['data']}/{key_data}\"\n",
    "    if n_s_list is not None:\n",
    "        filenames = [generate_file_name(path, \"data\", key_data, \"Xs\", n_s, \"raw\") for n_s in n_s_list]\n",
    "    else:\n",
    "        filenames = filter_filenames_in_folder(folder, \"raw\")\n",
    "    for filename in filenames:\n",
    "        Xs_raw = np.load(f\"{folder}/{filename}\")\n",
    "        Xs_feat = function_dict[key_feat](Xs_raw)[:, n_b:-n_b]\n",
    "        # save results\n",
    "        save_file(Xs_feat, path, 'data', key_data, \"Xs\", int(filename.split('_')[0]), key_feat)\n",
    "        # np_save_print(f\"{folder}/{filename.replace('raw', key_feat)}\", Xs_feat, \"Xs features\")            \n",
    "    return "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
